{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sn\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas.plotting import scatter_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(208, 61)\n",
      "       0       1       2       3       4       5       6       7       8   \\\n",
      "0  0.0200  0.0371  0.0428  0.0207  0.0954  0.0986  0.1539  0.1601  0.3109   \n",
      "1  0.0453  0.0523  0.0843  0.0689  0.1183  0.2583  0.2156  0.3481  0.3337   \n",
      "2  0.0262  0.0582  0.1099  0.1083  0.0974  0.2280  0.2431  0.3771  0.5598   \n",
      "3  0.0100  0.0171  0.0623  0.0205  0.0205  0.0368  0.1098  0.1276  0.0598   \n",
      "4  0.0762  0.0666  0.0481  0.0394  0.0590  0.0649  0.1209  0.2467  0.3564   \n",
      "\n",
      "       9   ...      51      52      53      54      55      56      57  \\\n",
      "0  0.2111  ...  0.0027  0.0065  0.0159  0.0072  0.0167  0.0180  0.0084   \n",
      "1  0.2872  ...  0.0084  0.0089  0.0048  0.0094  0.0191  0.0140  0.0049   \n",
      "2  0.6194  ...  0.0232  0.0166  0.0095  0.0180  0.0244  0.0316  0.0164   \n",
      "3  0.1264  ...  0.0121  0.0036  0.0150  0.0085  0.0073  0.0050  0.0044   \n",
      "4  0.4459  ...  0.0031  0.0054  0.0105  0.0110  0.0015  0.0072  0.0048   \n",
      "\n",
      "       58      59  60  \n",
      "0  0.0090  0.0032   R  \n",
      "1  0.0052  0.0044   R  \n",
      "2  0.0095  0.0078   R  \n",
      "3  0.0040  0.0117   R  \n",
      "4  0.0107  0.0094   R  \n",
      "\n",
      "[5 rows x 61 columns]\n",
      "(208,)\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('sonar.all-data',header=None)\n",
    "X = data[data.columns[0:60]]\n",
    "Y = data[data.columns[60]]\n",
    "print(data.shape)\n",
    "print(data.head())\n",
    "#data.hist()\n",
    "#plt.show()\n",
    "print(Y.shape)\n",
    "#data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#scatter_matrix(data)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode(labels):\n",
    "    n_labels = len(labels)\n",
    "    n_unique_labels = len(np.unique(labels))\n",
    "    one_hot_encode = np.zeros((n_labels,n_unique_labels))\n",
    "    one_hot_encode[np.arange(n_labels),labels] = 1\n",
    "    return one_hot_encode\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.utils import shuffle\n",
    "X,Y = shuffle(X,Y,random_state=1 )\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(Y)\n",
    "\n",
    "Y = encoder.transform(Y)\n",
    "Y= one_hot_encode(Y)\n",
    "\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,Y,test_size=0.2,random_state=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "learning_rate = 0.3\n",
    "epoch = 1000\n",
    "cost_history = np.empty(shape=[1],dtype=float)\n",
    "n_dim = X.shape[1]\n",
    "n_class = 20\n",
    "model_path = \"{}/model\".format(os.getcwd())\n",
    "n_hidden_1 = 60\n",
    "n_hidden_2 = 60\n",
    "n_hidden_3 = 60\n",
    "n_hidden_4 = 60\n",
    "x = tf.placeholder(tf.float32,[None,n_dim])\n",
    "W = tf.Variable(tf.zeros([n_dim,n_class]))\n",
    "b = tf.Variable(tf.zeros([n_class]))\n",
    "y_ = tf.placeholder(tf.float32,[None,n_class])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multilayer_perceptron(x,weights,biases):\n",
    "    layer_1 = tf.add(tf.matmul(x,weights['h1']),biases['b1'])\n",
    "    layer_1 = tf.nn.sigmoid(layer_1)\n",
    "    \n",
    "    layer_2 = tf.add(tf.matmul(layer_1,weights['h2']),biases['b2'])\n",
    "    layer_2 = tf.nn.sigmoid(layer_2)\n",
    "    \n",
    "    layer_3 = tf.add(tf.matmul(layer_2,weights['h3']),biases['b3'])\n",
    "    layer_3 = tf.nn.sigmoid(layer_3)\n",
    "    \n",
    "    layer_4 = tf.add(tf.matmul(layer_3,weights['h4']),biases['b4'])\n",
    "    layer_4 = tf.nn.relu(layer_4)\n",
    "    \n",
    "    out_layer = tf.matmul(layer_4,weights['out'])+biases['out']\n",
    "    return out_layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Placeholder_3:0\", shape=(?, 20), dtype=float32)\n",
      "Epoch : 0, Cost : 40.48017120361328, MSE : 1951.6847703607966, Train_Accuracy : 0.04836732894182205\n",
      "Epoch : 1, Cost : 66.25694274902344, MSE : 2210.1696026657537, Train_Accuracy : 0.1977434903383255\n",
      "Epoch : 2, Cost : 39.127201080322266, MSE : 567.0931149079453, Train_Accuracy : 0.1610044240951538\n",
      "Epoch : 3, Cost : 23.244112014770508, MSE : 158.42868176144393, Train_Accuracy : 0.10933718830347061\n",
      "Epoch : 4, Cost : 7.3778557777404785, MSE : 10.882234734611576, Train_Accuracy : 0.02913353592157364\n",
      "Epoch : 5, Cost : 3.2459664344787598, MSE : 0.8040119276221224, Train_Accuracy : 0.1610044240951538\n",
      "Epoch : 6, Cost : 3.2274563312530518, MSE : 0.7848584727607466, Train_Accuracy : 0.1610044240951538\n",
      "Epoch : 7, Cost : 3.2095284461975098, MSE : 0.7665183505679536, Train_Accuracy : 0.1610044240951538\n",
      "Epoch : 8, Cost : 3.1921563148498535, MSE : 0.7489550426803354, Train_Accuracy : 0.1610044240951538\n",
      "Epoch : 9, Cost : 3.1753408908843994, MSE : 0.7321449454307357, Train_Accuracy : 0.1610044240951538\n",
      "Epoch : 10, Cost : 3.159088134765625, MSE : 0.7160510750176993, Train_Accuracy : 0.1610044240951538\n",
      "Epoch : 11, Cost : 3.1433308124542236, MSE : 0.7006458939341282, Train_Accuracy : 0.1610044240951538\n",
      "Epoch : 12, Cost : 3.1281111240386963, MSE : 0.6859000628957449, Train_Accuracy : 0.1610044240951538\n",
      "Epoch : 13, Cost : 3.113391160964966, MSE : 0.6717864696062186, Train_Accuracy : 0.1610044240951538\n",
      "Epoch : 14, Cost : 3.0991623401641846, MSE : 0.6582800755624746, Train_Accuracy : 0.1610044240951538\n",
      "Epoch : 15, Cost : 3.0854074954986572, MSE : 0.6453514259300579, Train_Accuracy : 0.1610044240951538\n",
      "Epoch : 16, Cost : 3.072108745574951, MSE : 0.6329718194761681, Train_Accuracy : 0.1610044240951538\n",
      "Epoch : 17, Cost : 3.059267282485962, MSE : 0.6211210651311628, Train_Accuracy : 0.1610044240951538\n",
      "Epoch : 18, Cost : 3.0468497276306152, MSE : 0.6097755255173731, Train_Accuracy : 0.1610044240951538\n",
      "Epoch : 19, Cost : 3.034860372543335, MSE : 0.5989109106663385, Train_Accuracy : 0.1610044240951538\n",
      "Epoch : 20, Cost : 3.0232555866241455, MSE : 0.5885053354285994, Train_Accuracy : 0.1610044240951538\n",
      "Epoch : 21, Cost : 3.0120537281036377, MSE : 0.578538740255552, Train_Accuracy : 0.1610044240951538\n",
      "Epoch : 22, Cost : 3.0012288093566895, MSE : 0.5689876667381547, Train_Accuracy : 0.1610044240951538\n",
      "Epoch : 23, Cost : 2.990753173828125, MSE : 0.5598358160289559, Train_Accuracy : 0.1610044240951538\n",
      "Epoch : 24, Cost : 2.9806227684020996, MSE : 0.5510654091876203, Train_Accuracy : 0.1610044240951538\n",
      "Epoch : 25, Cost : 2.970817804336548, MSE : 0.5426588213459937, Train_Accuracy : 0.1610044240951538\n",
      "Epoch : 26, Cost : 2.9613232612609863, MSE : 0.5345995676385146, Train_Accuracy : 0.1610044240951538\n",
      "Epoch : 27, Cost : 2.952143430709839, MSE : 0.5268710032176629, Train_Accuracy : 0.1610044240951538\n",
      "Epoch : 28, Cost : 2.9432485103607178, MSE : 0.5194615048051267, Train_Accuracy : 0.1610044240951538\n",
      "Epoch : 29, Cost : 2.9346208572387695, MSE : 0.5123563325946227, Train_Accuracy : 0.1610044240951538\n",
      "Epoch : 30, Cost : 2.9262585639953613, MSE : 0.5055452200777336, Train_Accuracy : 0.1610044240951538\n",
      "Epoch : 31, Cost : 2.918152332305908, MSE : 0.4990127178247812, Train_Accuracy : 0.1610044240951538\n",
      "Epoch : 32, Cost : 2.9102771282196045, MSE : 0.49274967270351, Train_Accuracy : 0.1610044240951538\n",
      "Epoch : 33, Cost : 2.902639150619507, MSE : 0.4867435397529432, Train_Accuracy : 0.1610044240951538\n",
      "Epoch : 34, Cost : 2.89521861076355, MSE : 0.48098830106669327, Train_Accuracy : 0.1610044240951538\n",
      "Epoch : 35, Cost : 2.888000726699829, MSE : 0.47547187812479214, Train_Accuracy : 0.1610044240951538\n",
      "Epoch : 36, Cost : 2.8809919357299805, MSE : 0.47018826255532803, Train_Accuracy : 0.1610044240951538\n",
      "Epoch : 37, Cost : 2.874162197113037, MSE : 0.4651257795773622, Train_Accuracy : 0.1610044240951538\n",
      "Epoch : 38, Cost : 2.8675384521484375, MSE : 0.4602794226802463, Train_Accuracy : 0.1610044240951538\n",
      "Epoch : 39, Cost : 2.861072301864624, MSE : 0.4556433486586812, Train_Accuracy : 0.1610044240951538\n",
      "Epoch : 40, Cost : 2.8547914028167725, MSE : 0.4512092239031092, Train_Accuracy : 0.1610044240951538\n",
      "Epoch : 41, Cost : 2.848659038543701, MSE : 0.44696903325564064, Train_Accuracy : 0.1610044240951538\n",
      "Epoch : 42, Cost : 2.8427045345306396, MSE : 0.442919159573248, Train_Accuracy : 0.1610044240951538\n",
      "Epoch : 43, Cost : 2.836883306503296, MSE : 0.43905520861064623, Train_Accuracy : 0.1610044240951538\n",
      "Epoch : 44, Cost : 2.8312063217163086, MSE : 0.4353701780860873, Train_Accuracy : 0.1610044240951538\n",
      "Epoch : 45, Cost : 2.825676202774048, MSE : 0.4318599392073397, Train_Accuracy : 0.1610044240951538\n",
      "Epoch : 46, Cost : 2.8202812671661377, MSE : 0.42852002598873135, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 47, Cost : 2.8150172233581543, MSE : 0.42534527889875545, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 48, Cost : 2.809891939163208, MSE : 0.4223320646487919, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 49, Cost : 2.804859161376953, MSE : 0.4194750150634611, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 50, Cost : 2.7999684810638428, MSE : 0.416771063830204, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 51, Cost : 2.7951784133911133, MSE : 0.4142159076521716, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 52, Cost : 2.790522813796997, MSE : 0.41180618021937315, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 53, Cost : 2.785966157913208, MSE : 0.40953886732565975, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 54, Cost : 2.7815229892730713, MSE : 0.40740994882119064, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 55, Cost : 2.77718448638916, MSE : 0.4054167055736639, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 56, Cost : 2.772942543029785, MSE : 0.4035545540201933, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 57, Cost : 2.7687981128692627, MSE : 0.4018211825012225, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 58, Cost : 2.7647480964660645, MSE : 0.4002131413742692, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 59, Cost : 2.7608110904693604, MSE : 0.39872706374494615, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 60, Cost : 2.7569591999053955, MSE : 0.3973595648542316, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 61, Cost : 2.7531940937042236, MSE : 0.3961084362456644, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 62, Cost : 2.7495265007019043, MSE : 0.39497004027411137, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 63, Cost : 2.745934009552002, MSE : 0.3939413256396831, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 64, Cost : 2.742448091506958, MSE : 0.39302003470620744, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 65, Cost : 2.739025592803955, MSE : 0.39220304870947603, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 66, Cost : 2.7356975078582764, MSE : 0.39148678790245767, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 67, Cost : 2.7324531078338623, MSE : 0.39086939841037266, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 68, Cost : 2.7292826175689697, MSE : 0.39034713908260166, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 69, Cost : 2.726184606552124, MSE : 0.38991826596292356, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 70, Cost : 2.723172426223755, MSE : 0.3895795527353368, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 71, Cost : 2.720238447189331, MSE : 0.389328325014857, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 72, Cost : 2.717365264892578, MSE : 0.38916166303458755, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 73, Cost : 2.7145588397979736, MSE : 0.3890770676550678, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 74, Cost : 2.711843490600586, MSE : 0.3890716040771932, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 75, Cost : 2.709184169769287, MSE : 0.3891432407370665, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 76, Cost : 2.7065863609313965, MSE : 0.38928928002369945, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 77, Cost : 2.70406436920166, MSE : 0.38950688454667537, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 78, Cost : 2.70162034034729, MSE : 0.38979363976429005, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 79, Cost : 2.6992225646972656, MSE : 0.3901472498031202, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 80, Cost : 2.6968834400177, MSE : 0.39056561133491347, Train_Accuracy : 0.19771206378936768\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 81, Cost : 2.6946115493774414, MSE : 0.39104569144375145, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 82, Cost : 2.692391872406006, MSE : 0.3915854245633976, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 83, Cost : 2.6902341842651367, MSE : 0.39218297877637337, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 84, Cost : 2.688145160675049, MSE : 0.3928356402034894, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 85, Cost : 2.686099052429199, MSE : 0.3935410964058154, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 86, Cost : 2.6841182708740234, MSE : 0.3942975659788209, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 87, Cost : 2.68217396736145, MSE : 0.39510297865773425, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 88, Cost : 2.680285692214966, MSE : 0.3959546108291095, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 89, Cost : 2.6784634590148926, MSE : 0.39685129040473044, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 90, Cost : 2.6766769886016846, MSE : 0.3977906808950184, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 91, Cost : 2.6749465465545654, MSE : 0.39877094435267385, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 92, Cost : 2.6732568740844727, MSE : 0.3997899886710892, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 93, Cost : 2.671610116958618, MSE : 0.4008462299313453, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 94, Cost : 2.670008897781372, MSE : 0.40193765743033777, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 95, Cost : 2.668447971343994, MSE : 0.40306267462490397, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 96, Cost : 2.666936159133911, MSE : 0.40421930169010284, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 97, Cost : 2.665469169616699, MSE : 0.40540635295653343, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 98, Cost : 2.6640331745147705, MSE : 0.40662243750826804, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 99, Cost : 2.6626455783843994, MSE : 0.40786535602893065, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 100, Cost : 2.6612887382507324, MSE : 0.4091339449176091, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 101, Cost : 2.6599841117858887, MSE : 0.41042659927608327, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 102, Cost : 2.658689498901367, MSE : 0.41174180082841294, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 103, Cost : 2.657425880432129, MSE : 0.41307823660539206, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 104, Cost : 2.656214714050293, MSE : 0.4144350260854165, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 105, Cost : 2.6550495624542236, MSE : 0.41581026841814644, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 106, Cost : 2.653900623321533, MSE : 0.4172030318654746, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 107, Cost : 2.6527864933013916, MSE : 0.41861203300699074, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 108, Cost : 2.6516895294189453, MSE : 0.42003617730270015, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 109, Cost : 2.650639533996582, MSE : 0.4214745039114899, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 110, Cost : 2.649601936340332, MSE : 0.4229256219095275, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 111, Cost : 2.6486124992370605, MSE : 0.424388607839062, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 112, Cost : 2.647623062133789, MSE : 0.4258625843076342, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 113, Cost : 2.6466872692108154, MSE : 0.42734625395597586, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 114, Cost : 2.645756959915161, MSE : 0.42883898591959224, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 115, Cost : 2.6448707580566406, MSE : 0.4303400667630599, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 116, Cost : 2.6439924240112305, MSE : 0.43184848276782545, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 117, Cost : 2.6431479454040527, MSE : 0.4333633348153939, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 118, Cost : 2.6423234939575195, MSE : 0.4348837422979704, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 119, Cost : 2.6415131092071533, MSE : 0.43640874903618443, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 120, Cost : 2.6407315731048584, MSE : 0.4379383061439455, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 121, Cost : 2.6399614810943604, MSE : 0.4394711736287698, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 122, Cost : 2.6392269134521484, MSE : 0.4410069651891903, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 123, Cost : 2.638509511947632, MSE : 0.44254441414523354, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 124, Cost : 2.637799024581909, MSE : 0.4440838042433802, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 125, Cost : 2.637113332748413, MSE : 0.44562429042912105, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 126, Cost : 2.6364431381225586, MSE : 0.4471653536694098, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 127, Cost : 2.6357905864715576, MSE : 0.4487062455359981, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 128, Cost : 2.6351521015167236, MSE : 0.45024677776887423, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 129, Cost : 2.6345431804656982, MSE : 0.4517860379901742, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 130, Cost : 2.6339433193206787, MSE : 0.4533236887844191, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 131, Cost : 2.6333563327789307, MSE : 0.4548591583203355, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 132, Cost : 2.63277006149292, MSE : 0.4563924896397604, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 133, Cost : 2.6322202682495117, MSE : 0.45792256716296936, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 134, Cost : 2.631681203842163, MSE : 0.4594497557115855, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 135, Cost : 2.631164312362671, MSE : 0.4609734350689482, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 136, Cost : 2.630641222000122, MSE : 0.4624931828601083, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 137, Cost : 2.6301426887512207, MSE : 0.464008674953002, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 138, Cost : 2.629643440246582, MSE : 0.46551923256545835, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 139, Cost : 2.629166603088379, MSE : 0.46702541451902607, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 140, Cost : 2.628702163696289, MSE : 0.4685265933903314, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 141, Cost : 2.6282505989074707, MSE : 0.4700221872465311, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 142, Cost : 2.627805471420288, MSE : 0.47151219429220353, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 143, Cost : 2.627380132675171, MSE : 0.4729962955256153, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 144, Cost : 2.626960277557373, MSE : 0.47447415450889774, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 145, Cost : 2.6265506744384766, MSE : 0.4759460745341748, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 146, Cost : 2.626140594482422, MSE : 0.47741168899745373, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 147, Cost : 2.625753402709961, MSE : 0.47887042048930856, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 148, Cost : 2.6253669261932373, MSE : 0.48032211651328605, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 149, Cost : 2.6249938011169434, MSE : 0.4817669232473398, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 150, Cost : 2.6246325969696045, MSE : 0.4832047536773163, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 151, Cost : 2.624272346496582, MSE : 0.48463506981305476, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 152, Cost : 2.6239397525787354, MSE : 0.4860581807333272, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 153, Cost : 2.6235830783843994, MSE : 0.4874734982068715, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 154, Cost : 2.6232566833496094, MSE : 0.4888814609273599, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 155, Cost : 2.6229312419891357, MSE : 0.49028148761626705, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 156, Cost : 2.622628927230835, MSE : 0.4916734871884829, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 157, Cost : 2.622324228286743, MSE : 0.4930577752382917, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 158, Cost : 2.622009038925171, MSE : 0.4944338665100567, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 159, Cost : 2.6217100620269775, MSE : 0.4958020199880085, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 160, Cost : 2.6214253902435303, MSE : 0.49716173227604793, Train_Accuracy : 0.19771206378936768\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 161, Cost : 2.6211471557617188, MSE : 0.4985133068636552, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 162, Cost : 2.6208770275115967, MSE : 0.4998567061873736, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 163, Cost : 2.6206042766571045, MSE : 0.5011918228567765, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 164, Cost : 2.6203370094299316, MSE : 0.5025186559423362, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 165, Cost : 2.6200742721557617, MSE : 0.5038366086402203, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 166, Cost : 2.6198325157165527, MSE : 0.5051462996654449, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 167, Cost : 2.6195929050445557, MSE : 0.506447354555771, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 168, Cost : 2.6193525791168213, MSE : 0.5077400008402788, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 169, Cost : 2.619105815887451, MSE : 0.5090242166546166, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 170, Cost : 2.618889570236206, MSE : 0.510299683612447, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 171, Cost : 2.6186540126800537, MSE : 0.5115667177433141, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 172, Cost : 2.61843204498291, MSE : 0.5128251277874155, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 173, Cost : 2.618225336074829, MSE : 0.5140749314324079, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 174, Cost : 2.6180214881896973, MSE : 0.5153161873635203, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 175, Cost : 2.617809534072876, MSE : 0.5165487456414137, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 176, Cost : 2.6175997257232666, MSE : 0.5177727389995502, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 177, Cost : 2.6174089908599854, MSE : 0.518988040338114, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 178, Cost : 2.617218255996704, MSE : 0.5201950095996523, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 179, Cost : 2.61702561378479, MSE : 0.5213930968020069, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 180, Cost : 2.6168479919433594, MSE : 0.5225828831309554, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 181, Cost : 2.6166539192199707, MSE : 0.5237640152465988, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 182, Cost : 2.616485118865967, MSE : 0.5249367540712471, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 183, Cost : 2.6163277626037598, MSE : 0.5261009821380345, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 184, Cost : 2.6161344051361084, MSE : 0.5272568520575432, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 185, Cost : 2.6159791946411133, MSE : 0.528404105570946, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 186, Cost : 2.615800142288208, MSE : 0.5295431940198754, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 187, Cost : 2.6156508922576904, MSE : 0.5306738227852811, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 188, Cost : 2.6155014038085938, MSE : 0.5317960799988083, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 189, Cost : 2.615345001220703, MSE : 0.532910106700384, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 190, Cost : 2.615189552307129, MSE : 0.5340160635099366, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 191, Cost : 2.6150481700897217, MSE : 0.5351138716124385, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 192, Cost : 2.614894390106201, MSE : 0.536203203052524, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 193, Cost : 2.614762783050537, MSE : 0.5372843968869195, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 194, Cost : 2.6146292686462402, MSE : 0.5383576019446092, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 195, Cost : 2.61448335647583, MSE : 0.5394227086610661, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 196, Cost : 2.614356517791748, MSE : 0.540479843127384, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 197, Cost : 2.614224433898926, MSE : 0.5415291009986565, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 198, Cost : 2.614089012145996, MSE : 0.5425704159457295, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 199, Cost : 2.6139771938323975, MSE : 0.5436038599568545, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 200, Cost : 2.613847017288208, MSE : 0.5446293105139023, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 201, Cost : 2.613722562789917, MSE : 0.5456469034583069, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 202, Cost : 2.613612413406372, MSE : 0.5466568981550055, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 203, Cost : 2.613492727279663, MSE : 0.5476592529304823, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 204, Cost : 2.6133742332458496, MSE : 0.5486541539690738, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 205, Cost : 2.6132607460021973, MSE : 0.5496414845540555, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 206, Cost : 2.613161087036133, MSE : 0.5506210984650477, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 207, Cost : 2.6130428314208984, MSE : 0.5515931147601287, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 208, Cost : 2.612945556640625, MSE : 0.5525580181929017, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 209, Cost : 2.61283540725708, MSE : 0.5535154436291304, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 210, Cost : 2.6127331256866455, MSE : 0.5544655136238532, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 211, Cost : 2.61265230178833, MSE : 0.5554083383239904, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 212, Cost : 2.6125385761260986, MSE : 0.5563437478561508, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 213, Cost : 2.612445592880249, MSE : 0.5572721050108416, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 214, Cost : 2.6123571395874023, MSE : 0.5581933408057631, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 215, Cost : 2.612272262573242, MSE : 0.5591074121642619, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 216, Cost : 2.6121692657470703, MSE : 0.560014403772087, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 217, Cost : 2.612081289291382, MSE : 0.560914657017111, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 218, Cost : 2.611992359161377, MSE : 0.5618077635583052, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 219, Cost : 2.6119039058685303, MSE : 0.5626941968241292, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 220, Cost : 2.6118268966674805, MSE : 0.5635738538848473, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 221, Cost : 2.6117420196533203, MSE : 0.5644463532083107, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 222, Cost : 2.611666679382324, MSE : 0.5653123095772522, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 223, Cost : 2.6115798950195312, MSE : 0.566171584573971, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 224, Cost : 2.6115047931671143, MSE : 0.5670243937973758, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 225, Cost : 2.611422538757324, MSE : 0.567870693028441, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 226, Cost : 2.6113436222076416, MSE : 0.568710448432403, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 227, Cost : 2.611278772354126, MSE : 0.5695438615494125, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 228, Cost : 2.611196517944336, MSE : 0.5703707130477901, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 229, Cost : 2.6111252307891846, MSE : 0.5711912955769342, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 230, Cost : 2.611065626144409, MSE : 0.5720053969784822, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 231, Cost : 2.6109938621520996, MSE : 0.5728134680593695, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 232, Cost : 2.6109209060668945, MSE : 0.5736152948958925, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 233, Cost : 2.61086368560791, MSE : 0.5744109368706253, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 234, Cost : 2.610793113708496, MSE : 0.5752005008502438, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 235, Cost : 2.6107263565063477, MSE : 0.5759840243810147, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 236, Cost : 2.610654354095459, MSE : 0.5767614602280801, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 237, Cost : 2.6105988025665283, MSE : 0.5775330376939257, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 238, Cost : 2.610543966293335, MSE : 0.5782988066122747, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 239, Cost : 2.6104817390441895, MSE : 0.5790586494538049, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 240, Cost : 2.6104140281677246, MSE : 0.5798127110799894, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 241, Cost : 2.6103711128234863, MSE : 0.580560954201526, Train_Accuracy : 0.19771206378936768\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 242, Cost : 2.610307455062866, MSE : 0.5813035756512362, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 243, Cost : 2.610243797302246, MSE : 0.5820405120770974, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 244, Cost : 2.6101958751678467, MSE : 0.5827718023907452, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 245, Cost : 2.6101479530334473, MSE : 0.5834976961040278, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 246, Cost : 2.610090494155884, MSE : 0.5842179200266852, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 247, Cost : 2.610034465789795, MSE : 0.5849327966099049, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 248, Cost : 2.609981060028076, MSE : 0.5856420964503832, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 249, Cost : 2.609933376312256, MSE : 0.5863462238390397, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 250, Cost : 2.6098837852478027, MSE : 0.587044989228223, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 251, Cost : 2.609830617904663, MSE : 0.5877384109914813, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 252, Cost : 2.6097822189331055, MSE : 0.5884265947408361, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 253, Cost : 2.6097350120544434, MSE : 0.5891095561115177, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 254, Cost : 2.6096925735473633, MSE : 0.5897873407665124, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 255, Cost : 2.609637975692749, MSE : 0.5904600880245131, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 256, Cost : 2.6095855236053467, MSE : 0.5911278476095945, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 257, Cost : 2.6095595359802246, MSE : 0.5917904743767419, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 258, Cost : 2.6095130443573, MSE : 0.5924481957813806, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 259, Cost : 2.6094677448272705, MSE : 0.5931010968000404, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 260, Cost : 2.609426498413086, MSE : 0.5937489703112924, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 261, Cost : 2.6093852519989014, MSE : 0.5943920048841989, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 262, Cost : 2.609351873397827, MSE : 0.5950302005543124, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 263, Cost : 2.6093039512634277, MSE : 0.5956634817400926, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 264, Cost : 2.609257221221924, MSE : 0.5962922902680583, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 265, Cost : 2.6092162132263184, MSE : 0.5969163865843665, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 266, Cost : 2.6091768741607666, MSE : 0.597535734529465, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 267, Cost : 2.609147071838379, MSE : 0.5981505359200742, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 268, Cost : 2.609117269515991, MSE : 0.5987608452942907, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 269, Cost : 2.6090705394744873, MSE : 0.5993665901891899, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 270, Cost : 2.609027862548828, MSE : 0.5999677051655148, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 271, Cost : 2.609001398086548, MSE : 0.6005645609490636, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 272, Cost : 2.60896635055542, MSE : 0.6011568573924269, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 273, Cost : 2.608935594558716, MSE : 0.6017448206457942, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 274, Cost : 2.6088945865631104, MSE : 0.602328452023376, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 275, Cost : 2.608853816986084, MSE : 0.6029078780288745, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 276, Cost : 2.6088297367095947, MSE : 0.6034829085266806, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 277, Cost : 2.60880184173584, MSE : 0.6040537418135651, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 278, Cost : 2.608771562576294, MSE : 0.6046203369912426, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 279, Cost : 2.6087231636047363, MSE : 0.6051828910464675, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 280, Cost : 2.608707904815674, MSE : 0.6057412323133503, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 281, Cost : 2.608673334121704, MSE : 0.606295533025632, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 282, Cost : 2.6086483001708984, MSE : 0.6068458685645628, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 283, Cost : 2.6086204051971436, MSE : 0.6073922498554943, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 284, Cost : 2.6085877418518066, MSE : 0.6079345928321949, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 285, Cost : 2.6085543632507324, MSE : 0.6084730430892196, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 286, Cost : 2.608527421951294, MSE : 0.6090074647499923, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 287, Cost : 2.6084964275360107, MSE : 0.6095380085842553, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 288, Cost : 2.608474016189575, MSE : 0.6100646312400236, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 289, Cost : 2.608445882797241, MSE : 0.6105874625633763, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 290, Cost : 2.6084282398223877, MSE : 0.611106555006235, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 291, Cost : 2.6083948612213135, MSE : 0.6116219322120242, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 292, Cost : 2.608370780944824, MSE : 0.6121335290421848, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 293, Cost : 2.6083359718322754, MSE : 0.6126414525050853, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 294, Cost : 2.6083197593688965, MSE : 0.6131458279344635, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 295, Cost : 2.6083061695098877, MSE : 0.6136466047316276, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 296, Cost : 2.6082682609558105, MSE : 0.6141437472962645, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 297, Cost : 2.608240842819214, MSE : 0.6146372928637504, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 298, Cost : 2.6082215309143066, MSE : 0.6151273170214461, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 299, Cost : 2.608196973800659, MSE : 0.6156137652180128, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 300, Cost : 2.6081807613372803, MSE : 0.6160968169485214, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 301, Cost : 2.6081621646881104, MSE : 0.6165765801673666, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 302, Cost : 2.608135223388672, MSE : 0.617052814835742, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 303, Cost : 2.6081132888793945, MSE : 0.6175257120495992, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 304, Cost : 2.6080846786499023, MSE : 0.6179952435442246, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 305, Cost : 2.6080687046051025, MSE : 0.6184613655414755, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 306, Cost : 2.6080424785614014, MSE : 0.6189242433215795, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 307, Cost : 2.6080284118652344, MSE : 0.6193838332925097, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 308, Cost : 2.6080098152160645, MSE : 0.6198401618428858, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 309, Cost : 2.6079843044281006, MSE : 0.6202931617413262, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 310, Cost : 2.6079699993133545, MSE : 0.6207431457921272, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 311, Cost : 2.607962131500244, MSE : 0.6211898856621718, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 312, Cost : 2.6079294681549072, MSE : 0.6216335999197588, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 313, Cost : 2.607900857925415, MSE : 0.6220741019344302, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 314, Cost : 2.6078848838806152, MSE : 0.622511505203319, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 315, Cost : 2.6078670024871826, MSE : 0.62294591309993, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 316, Cost : 2.607858896255493, MSE : 0.6233772085903878, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 317, Cost : 2.6078367233276367, MSE : 0.6238055027372845, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 318, Cost : 2.6078197956085205, MSE : 0.6242307821976737, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 319, Cost : 2.6078011989593506, MSE : 0.6246531097040374, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 320, Cost : 2.6077873706817627, MSE : 0.6250724610729007, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 321, Cost : 2.6077632904052734, MSE : 0.6254889798087186, Train_Accuracy : 0.19771206378936768\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 322, Cost : 2.60774564743042, MSE : 0.6259025668899567, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 323, Cost : 2.607740640640259, MSE : 0.6263133022313812, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 324, Cost : 2.6077229976654053, MSE : 0.6267212148039983, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 325, Cost : 2.6077067852020264, MSE : 0.6271263360576709, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 326, Cost : 2.6076860427856445, MSE : 0.6275286103396137, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 327, Cost : 2.6076738834381104, MSE : 0.6279281294964435, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 328, Cost : 2.607649564743042, MSE : 0.6283249067536102, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 329, Cost : 2.6076364517211914, MSE : 0.6287187849110837, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 330, Cost : 2.607619524002075, MSE : 0.6291100936639771, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 331, Cost : 2.6076135635375977, MSE : 0.6294987606645933, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 332, Cost : 2.6075971126556396, MSE : 0.6298847332743455, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 333, Cost : 2.6075820922851562, MSE : 0.6302680539158658, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 334, Cost : 2.607571840286255, MSE : 0.6306487665804349, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 335, Cost : 2.607548713684082, MSE : 0.6310268138225017, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 336, Cost : 2.6075439453125, MSE : 0.6314023735435352, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 337, Cost : 2.60752534866333, MSE : 0.6317752756437367, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 338, Cost : 2.607516050338745, MSE : 0.6321456902889, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 339, Cost : 2.6075048446655273, MSE : 0.6325135639324708, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 340, Cost : 2.6074821949005127, MSE : 0.6328790293986575, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 341, Cost : 2.6074678897857666, MSE : 0.6332420151205389, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 342, Cost : 2.6074628829956055, MSE : 0.6336025852320117, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 343, Cost : 2.607449531555176, MSE : 0.6339605748654717, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 344, Cost : 2.6074390411376953, MSE : 0.6343161730816016, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 345, Cost : 2.607426404953003, MSE : 0.6346693288362367, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 346, Cost : 2.607417345046997, MSE : 0.6350201474110176, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 347, Cost : 2.607412338256836, MSE : 0.6353686094990983, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 348, Cost : 2.607394218444824, MSE : 0.6357147089086773, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 349, Cost : 2.6073720455169678, MSE : 0.6360584842988802, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 350, Cost : 2.6073577404022217, MSE : 0.6364000349909901, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 351, Cost : 2.607346296310425, MSE : 0.636739182253361, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 352, Cost : 2.60733962059021, MSE : 0.6370761698389181, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 353, Cost : 2.607332229614258, MSE : 0.637410808986498, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 354, Cost : 2.6073319911956787, MSE : 0.6377432346291523, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 355, Cost : 2.607326030731201, MSE : 0.6380734287206081, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 356, Cost : 2.6073036193847656, MSE : 0.6384014794271269, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 357, Cost : 2.607296943664551, MSE : 0.6387273507005428, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 358, Cost : 2.60728120803833, MSE : 0.6390509913004944, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 359, Cost : 2.607264995574951, MSE : 0.6393724594310691, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 360, Cost : 2.607252836227417, MSE : 0.6396918099652318, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 361, Cost : 2.607252597808838, MSE : 0.6400091446515364, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 362, Cost : 2.60723614692688, MSE : 0.6403243715380316, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 363, Cost : 2.6072354316711426, MSE : 0.6406375305255148, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 364, Cost : 2.607224702835083, MSE : 0.6409485146464154, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 365, Cost : 2.607212781906128, MSE : 0.6412574717320402, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 366, Cost : 2.607212781906128, MSE : 0.6415644027735943, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 367, Cost : 2.6072041988372803, MSE : 0.6418693301305124, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 368, Cost : 2.6071925163269043, MSE : 0.6421722726587121, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 369, Cost : 2.6071839332580566, MSE : 0.6424732370071919, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 370, Cost : 2.6071689128875732, MSE : 0.6427722601400379, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 371, Cost : 2.607163429260254, MSE : 0.6430692560819825, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 372, Cost : 2.607151508331299, MSE : 0.6433643939146453, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 373, Cost : 2.6071486473083496, MSE : 0.6436575403825621, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 374, Cost : 2.607137680053711, MSE : 0.6439488288315266, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 375, Cost : 2.6071279048919678, MSE : 0.6442382672645156, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 376, Cost : 2.607114553451538, MSE : 0.6445258462638525, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 377, Cost : 2.607109308242798, MSE : 0.644811466252288, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 378, Cost : 2.607099771499634, MSE : 0.6450952233451311, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 379, Cost : 2.6070964336395264, MSE : 0.6453771784438781, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 380, Cost : 2.6070966720581055, MSE : 0.6456572521446233, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 381, Cost : 2.607081651687622, MSE : 0.6459355064766609, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 382, Cost : 2.607071876525879, MSE : 0.646211928422856, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 383, Cost : 2.607062816619873, MSE : 0.6464865728339415, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 384, Cost : 2.607057809829712, MSE : 0.6467594561744386, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 385, Cost : 2.607055902481079, MSE : 0.647030664127643, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 386, Cost : 2.6070473194122314, MSE : 0.647300098935368, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 387, Cost : 2.6070404052734375, MSE : 0.6475678019001979, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 388, Cost : 2.6070306301116943, MSE : 0.6478337564841828, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 389, Cost : 2.607022762298584, MSE : 0.6480980334707281, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 390, Cost : 2.6070096492767334, MSE : 0.6483605765131397, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 391, Cost : 2.607006072998047, MSE : 0.6486214864028556, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 392, Cost : 2.606999158859253, MSE : 0.6488807490448102, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 393, Cost : 2.6069934368133545, MSE : 0.6491383343512259, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 394, Cost : 2.6069936752319336, MSE : 0.6493942536290157, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 395, Cost : 2.606987476348877, MSE : 0.6496485216794295, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 396, Cost : 2.606980323791504, MSE : 0.6499012761068487, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 397, Cost : 2.6069788932800293, MSE : 0.650152349796845, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 398, Cost : 2.6069679260253906, MSE : 0.6504018635308861, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 399, Cost : 2.606961727142334, MSE : 0.650649712784916, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 400, Cost : 2.6069507598876953, MSE : 0.6508960950385252, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 401, Cost : 2.6069533824920654, MSE : 0.6511408443908274, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 402, Cost : 2.6069483757019043, MSE : 0.6513840705597118, Train_Accuracy : 0.19771206378936768\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 403, Cost : 2.606928586959839, MSE : 0.651625739524812, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 404, Cost : 2.6069228649139404, MSE : 0.651865824129099, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 405, Cost : 2.6069250106811523, MSE : 0.6521044887487604, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 406, Cost : 2.606920003890991, MSE : 0.652341622980706, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 407, Cost : 2.6068978309631348, MSE : 0.6525772732998021, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 408, Cost : 2.6068975925445557, MSE : 0.6528114163391081, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 409, Cost : 2.6068966388702393, MSE : 0.6530441001602842, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 410, Cost : 2.606893539428711, MSE : 0.6532752729306845, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 411, Cost : 2.606884002685547, MSE : 0.6535050699369218, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 412, Cost : 2.606889486312866, MSE : 0.6537334844542128, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 413, Cost : 2.6068942546844482, MSE : 0.6539603876986604, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 414, Cost : 2.606874704360962, MSE : 0.6541858958936431, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 415, Cost : 2.606877565383911, MSE : 0.6544100029387678, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 416, Cost : 2.6068732738494873, MSE : 0.6546327492360388, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 417, Cost : 2.606869697570801, MSE : 0.6548540087212725, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 418, Cost : 2.6068568229675293, MSE : 0.6550739521290938, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 419, Cost : 2.6068549156188965, MSE : 0.65529248097408, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 420, Cost : 2.606849431991577, MSE : 0.655509713583307, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 421, Cost : 2.6068530082702637, MSE : 0.6557256563625408, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 422, Cost : 2.606832265853882, MSE : 0.6559402119112986, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 423, Cost : 2.6068243980407715, MSE : 0.656153454724004, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 424, Cost : 2.6068170070648193, MSE : 0.6563653907443752, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 425, Cost : 2.6068172454833984, MSE : 0.6565760034488652, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 426, Cost : 2.606821298599243, MSE : 0.6567853085225218, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 427, Cost : 2.606811046600342, MSE : 0.6569932914000021, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 428, Cost : 2.6068074703216553, MSE : 0.6571999905656593, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 429, Cost : 2.606809139251709, MSE : 0.6574054636267638, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 430, Cost : 2.6068115234375, MSE : 0.6576096489255463, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 431, Cost : 2.606799840927124, MSE : 0.657812621053665, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 432, Cost : 2.606797933578491, MSE : 0.658014307540646, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 433, Cost : 2.6067898273468018, MSE : 0.6582147860547725, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 434, Cost : 2.60678768157959, MSE : 0.6584140112647825, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 435, Cost : 2.6067824363708496, MSE : 0.6586121047064769, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 436, Cost : 2.606778383255005, MSE : 0.6588089148821655, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 437, Cost : 2.606778383255005, MSE : 0.6590045418671326, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 438, Cost : 2.6067724227905273, MSE : 0.6591989733122846, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 439, Cost : 2.6067662239074707, MSE : 0.6593922730736214, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 440, Cost : 2.6067585945129395, MSE : 0.6595843686346912, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 441, Cost : 2.6067659854888916, MSE : 0.6597752821034777, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 442, Cost : 2.606753349304199, MSE : 0.6599650761259895, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 443, Cost : 2.6067557334899902, MSE : 0.6601537004492924, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 444, Cost : 2.6067538261413574, MSE : 0.660341195447496, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 445, Cost : 2.606739044189453, MSE : 0.6605275013469857, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 446, Cost : 2.606739044189453, MSE : 0.6607127436183147, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 447, Cost : 2.6067395210266113, MSE : 0.6608967762883212, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 448, Cost : 2.6067287921905518, MSE : 0.6610798046276785, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 449, Cost : 2.6067349910736084, MSE : 0.6612616586877207, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 450, Cost : 2.6067261695861816, MSE : 0.6614424617448776, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 451, Cost : 2.606729030609131, MSE : 0.6616221375594104, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 452, Cost : 2.606717348098755, MSE : 0.6618007596049185, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 453, Cost : 2.6067190170288086, MSE : 0.661978316215851, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 454, Cost : 2.6067097187042236, MSE : 0.6621548195051123, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 455, Cost : 2.6067073345184326, MSE : 0.6623302870126702, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 456, Cost : 2.6067044734954834, MSE : 0.6625047035683729, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 457, Cost : 2.606703758239746, MSE : 0.6626780893828895, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 458, Cost : 2.6067023277282715, MSE : 0.6628504320641034, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 459, Cost : 2.606700897216797, MSE : 0.6630217382458501, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 460, Cost : 2.606701612472534, MSE : 0.6631919794939553, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 461, Cost : 2.6066904067993164, MSE : 0.6633612222969107, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 462, Cost : 2.6066882610321045, MSE : 0.6635294798429118, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 463, Cost : 2.606685161590576, MSE : 0.663696749185464, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 464, Cost : 2.606691837310791, MSE : 0.6638630385329267, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 465, Cost : 2.606684923171997, MSE : 0.6640282822528307, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 466, Cost : 2.606679677963257, MSE : 0.6641925522548127, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 467, Cost : 2.6066832542419434, MSE : 0.6643558894048934, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 468, Cost : 2.6066739559173584, MSE : 0.6645182513392192, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 469, Cost : 2.606680154800415, MSE : 0.6646796954021366, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 470, Cost : 2.606672763824463, MSE : 0.6648401736045503, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 471, Cost : 2.6066737174987793, MSE : 0.664999730758797, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 472, Cost : 2.606661081314087, MSE : 0.6651582879724386, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 473, Cost : 2.6066532135009766, MSE : 0.6653159485316028, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 474, Cost : 2.6066577434539795, MSE : 0.6654726920548139, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 475, Cost : 2.60664963722229, MSE : 0.6656284828777459, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 476, Cost : 2.6066524982452393, MSE : 0.6657833934949928, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 477, Cost : 2.6066536903381348, MSE : 0.6659374278956285, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 478, Cost : 2.6066484451293945, MSE : 0.6660905477973691, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 479, Cost : 2.6066412925720215, MSE : 0.6662427612060688, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 480, Cost : 2.6066417694091797, MSE : 0.6663940572355548, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 481, Cost : 2.606642723083496, MSE : 0.6665444222632928, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 482, Cost : 2.6066319942474365, MSE : 0.6666939980234824, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 483, Cost : 2.606628894805908, MSE : 0.666842666336614, Train_Accuracy : 0.19771206378936768\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 484, Cost : 2.6066324710845947, MSE : 0.6669905591889791, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 485, Cost : 2.6066224575042725, MSE : 0.6671375206250594, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 486, Cost : 2.6066229343414307, MSE : 0.6672836751544023, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 487, Cost : 2.6066174507141113, MSE : 0.6674289154655036, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 488, Cost : 2.6066205501556396, MSE : 0.6675733541689508, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 489, Cost : 2.6066126823425293, MSE : 0.6677169374876805, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 490, Cost : 2.6066172122955322, MSE : 0.6678596932277134, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 491, Cost : 2.6066133975982666, MSE : 0.6680016389542773, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 492, Cost : 2.6066172122955322, MSE : 0.668142737305026, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 493, Cost : 2.606623411178589, MSE : 0.6682830680518587, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 494, Cost : 2.6066181659698486, MSE : 0.6684225407648289, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 495, Cost : 2.606616735458374, MSE : 0.6685612433611694, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 496, Cost : 2.606616735458374, MSE : 0.6686992090927255, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 497, Cost : 2.6066153049468994, MSE : 0.6688363056313291, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 498, Cost : 2.606616258621216, MSE : 0.6689726409675038, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 499, Cost : 2.606611490249634, MSE : 0.6691082083931159, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 500, Cost : 2.6065993309020996, MSE : 0.6692429761953644, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 501, Cost : 2.606597661972046, MSE : 0.6693770027802766, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 502, Cost : 2.6065967082977295, MSE : 0.669510242059095, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 503, Cost : 2.606600046157837, MSE : 0.6696427021152356, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 504, Cost : 2.6065967082977295, MSE : 0.6697744112550854, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 505, Cost : 2.606593132019043, MSE : 0.669905417844447, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 506, Cost : 2.606588125228882, MSE : 0.6700356019677975, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 507, Cost : 2.606588840484619, MSE : 0.6701650910727317, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 508, Cost : 2.6065828800201416, MSE : 0.6702938480483955, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 509, Cost : 2.606581926345825, MSE : 0.6704218548230378, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 510, Cost : 2.6065709590911865, MSE : 0.6705491521312515, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 511, Cost : 2.606570243835449, MSE : 0.6706757492166153, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 512, Cost : 2.6065738201141357, MSE : 0.6708016000397735, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 513, Cost : 2.6065728664398193, MSE : 0.6709267458810546, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 514, Cost : 2.6065754890441895, MSE : 0.6710512265837189, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 515, Cost : 2.606569528579712, MSE : 0.6711750034704751, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 516, Cost : 2.606562852859497, MSE : 0.6712980580244925, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 517, Cost : 2.60656476020813, MSE : 0.67142041545248, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 518, Cost : 2.6065638065338135, MSE : 0.6715421190041146, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 519, Cost : 2.606564998626709, MSE : 0.6716630846725717, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 520, Cost : 2.6065659523010254, MSE : 0.671783361460149, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 521, Cost : 2.6065502166748047, MSE : 0.6719030488629621, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 522, Cost : 2.6065518856048584, MSE : 0.6720220028706397, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 523, Cost : 2.6065497398376465, MSE : 0.6721402674639599, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 524, Cost : 2.6065564155578613, MSE : 0.6722578962379699, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 525, Cost : 2.6065568923950195, MSE : 0.6723748441007658, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 526, Cost : 2.6065597534179688, MSE : 0.6724911946848982, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 527, Cost : 2.60654878616333, MSE : 0.6726068640858918, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 528, Cost : 2.6065521240234375, MSE : 0.6727219314845627, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 529, Cost : 2.606549024581909, MSE : 0.6728363116555611, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 530, Cost : 2.606546640396118, MSE : 0.6729500314821316, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 531, Cost : 2.6065478324890137, MSE : 0.6730631310570293, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 532, Cost : 2.60654354095459, MSE : 0.6731756427184449, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 533, Cost : 2.6065468788146973, MSE : 0.6732874772864542, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 534, Cost : 2.6065478324890137, MSE : 0.6733987341582949, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 535, Cost : 2.6065430641174316, MSE : 0.6735094034132318, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 536, Cost : 2.6065402030944824, MSE : 0.6736193897446279, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 537, Cost : 2.6065433025360107, MSE : 0.6737287721928061, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 538, Cost : 2.6065447330474854, MSE : 0.6738376332088285, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 539, Cost : 2.606544017791748, MSE : 0.6739458290077844, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 540, Cost : 2.6065385341644287, MSE : 0.674053465972557, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 541, Cost : 2.606541395187378, MSE : 0.6741604666202986, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 542, Cost : 2.6065425872802734, MSE : 0.674266879598715, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 543, Cost : 2.606541872024536, MSE : 0.6743727633182244, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 544, Cost : 2.606539249420166, MSE : 0.6744779998703078, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 545, Cost : 2.606532096862793, MSE : 0.6745826522034026, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 546, Cost : 2.6065218448638916, MSE : 0.6746867686376699, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 547, Cost : 2.6065244674682617, MSE : 0.6747903887074278, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 548, Cost : 2.60652494430542, MSE : 0.6748933881967717, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 549, Cost : 2.6065189838409424, MSE : 0.674995780584296, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 550, Cost : 2.606519937515259, MSE : 0.6750976337390951, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 551, Cost : 2.6065237522125244, MSE : 0.6751989655950263, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 552, Cost : 2.60652232170105, MSE : 0.675299741049438, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 553, Cost : 2.6065163612365723, MSE : 0.6753999170244128, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 554, Cost : 2.6065192222595215, MSE : 0.6754995569709557, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 555, Cost : 2.60652232170105, MSE : 0.6755986779682003, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 556, Cost : 2.6065096855163574, MSE : 0.6756972439746387, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 557, Cost : 2.606509208679199, MSE : 0.675795251614931, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 558, Cost : 2.6065127849578857, MSE : 0.6758927424719503, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 559, Cost : 2.6065120697021484, MSE : 0.6759897252949717, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 560, Cost : 2.606501579284668, MSE : 0.6760862125744006, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 561, Cost : 2.6065046787261963, MSE : 0.6761821055609711, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 562, Cost : 2.6065006256103516, MSE : 0.6762775156589098, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 563, Cost : 2.606499433517456, MSE : 0.6763724733546973, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 564, Cost : 2.606501579284668, MSE : 0.6764668994100368, Train_Accuracy : 0.19771206378936768\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 565, Cost : 2.6064999103546143, MSE : 0.6765607910871, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 566, Cost : 2.606496810913086, MSE : 0.6766541556339848, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 567, Cost : 2.6065032482147217, MSE : 0.6767470400050407, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 568, Cost : 2.6065003871917725, MSE : 0.6768394408947365, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 569, Cost : 2.6065011024475098, MSE : 0.6769313333700218, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 570, Cost : 2.6065046787261963, MSE : 0.677022728858975, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 571, Cost : 2.606506824493408, MSE : 0.6771136063932931, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 572, Cost : 2.60650634765625, MSE : 0.6772040242896524, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 573, Cost : 2.606508493423462, MSE : 0.6772939446652211, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 574, Cost : 2.606497287750244, MSE : 0.6773834228706397, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 575, Cost : 2.60650372505188, MSE : 0.6774723878628822, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 576, Cost : 2.6064915657043457, MSE : 0.6775608695068316, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 577, Cost : 2.606497049331665, MSE : 0.6776489238339944, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 578, Cost : 2.606487989425659, MSE : 0.6777364998634049, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 579, Cost : 2.606491804122925, MSE : 0.6778236301932226, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 580, Cost : 2.606494426727295, MSE : 0.6779102110589738, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 581, Cost : 2.606487989425659, MSE : 0.6779963923477859, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 582, Cost : 2.606480598449707, MSE : 0.6780820764849753, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 583, Cost : 2.6064791679382324, MSE : 0.6781673128759094, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 584, Cost : 2.6064791679382324, MSE : 0.6782521470068549, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 585, Cost : 2.6064796447753906, MSE : 0.6783364958677555, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 586, Cost : 2.6064765453338623, MSE : 0.678420383073928, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 587, Cost : 2.606478214263916, MSE : 0.6785038367128579, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 588, Cost : 2.6064796447753906, MSE : 0.6785868699950866, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 589, Cost : 2.6064858436584473, MSE : 0.6786694531634064, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 590, Cost : 2.6064836978912354, MSE : 0.6787515899168791, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 591, Cost : 2.6064867973327637, MSE : 0.67883330314763, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 592, Cost : 2.606482744216919, MSE : 0.678914559709958, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 593, Cost : 2.606483221054077, MSE : 0.6789953868869549, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 594, Cost : 2.6064870357513428, MSE : 0.6790758274005108, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 595, Cost : 2.6064696311950684, MSE : 0.6791558477474383, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 596, Cost : 2.6064703464508057, MSE : 0.6792354216702331, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 597, Cost : 2.6064724922180176, MSE : 0.6793145819206591, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 598, Cost : 2.606473684310913, MSE : 0.6793933676033082, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 599, Cost : 2.606475830078125, MSE : 0.6794717386206929, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 600, Cost : 2.606471300125122, MSE : 0.6795496821459911, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 601, Cost : 2.6064722537994385, MSE : 0.6796271769763689, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 602, Cost : 2.606472969055176, MSE : 0.6797042814026358, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 603, Cost : 2.606473445892334, MSE : 0.6797809947622573, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 604, Cost : 2.606476306915283, MSE : 0.6798573281349282, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 605, Cost : 2.606473684310913, MSE : 0.6799332796688555, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 606, Cost : 2.6064743995666504, MSE : 0.6800087822123261, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 607, Cost : 2.6064727306365967, MSE : 0.6800839317969324, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 608, Cost : 2.6064765453338623, MSE : 0.6801586862231405, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 609, Cost : 2.606476306915283, MSE : 0.680233067785508, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 610, Cost : 2.606478214263916, MSE : 0.6803070514448324, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 611, Cost : 2.60646653175354, MSE : 0.6803806469291136, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 612, Cost : 2.6064693927764893, MSE : 0.6804538494925358, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 613, Cost : 2.606470823287964, MSE : 0.6805267030595451, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 614, Cost : 2.606458902359009, MSE : 0.6805991276354197, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 615, Cost : 2.6064610481262207, MSE : 0.6806712141990486, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 616, Cost : 2.6064629554748535, MSE : 0.6807429119572641, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 617, Cost : 2.606462240219116, MSE : 0.6808142585158989, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 618, Cost : 2.6064624786376953, MSE : 0.6808852587079738, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 619, Cost : 2.6064600944519043, MSE : 0.6809558925954027, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 620, Cost : 2.6064600944519043, MSE : 0.6810260744182657, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 621, Cost : 2.606459617614746, MSE : 0.6810959528269418, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 622, Cost : 2.6064562797546387, MSE : 0.6811654624004614, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 623, Cost : 2.6064577102661133, MSE : 0.68123461854011, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 624, Cost : 2.606457471847534, MSE : 0.6813034255311124, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 625, Cost : 2.606456995010376, MSE : 0.6813719124005927, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 626, Cost : 2.6064493656158447, MSE : 0.6814400786977526, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 627, Cost : 2.6064553260803223, MSE : 0.6815077711941953, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 628, Cost : 2.6064555644989014, MSE : 0.6815751692414486, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 629, Cost : 2.606457233428955, MSE : 0.6816422252899019, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 630, Cost : 2.606459856033325, MSE : 0.6817089509500587, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 631, Cost : 2.606456756591797, MSE : 0.6817753593046861, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 632, Cost : 2.6064605712890625, MSE : 0.6818414249863733, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 633, Cost : 2.606459617614746, MSE : 0.6819071280168575, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 634, Cost : 2.606455087661743, MSE : 0.6819724625947651, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 635, Cost : 2.6064586639404297, MSE : 0.6820374956901522, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 636, Cost : 2.6064603328704834, MSE : 0.6821021931060564, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 637, Cost : 2.6064462661743164, MSE : 0.6821665856651129, Train_Accuracy : 0.19771206378936768\n",
      "Epoch : 638, Cost : 2.606444835662842, MSE : 0.6822306712726127, Train_Accuracy : 0.19771206378936768\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-4aa32c70a16a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeed_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m     \u001b[0mcost\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcost_function\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeed_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m     \u001b[0mcost_history\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcost_history\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcost\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0mcorrect_prediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mequal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    955\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    956\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 957\u001b[0;31m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0m\u001b[1;32m    958\u001b[0m                          run_metadata_ptr)\n\u001b[1;32m    959\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1148\u001b[0m             \u001b[0mfeed_handles\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msubfeed_t\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubfeed_val\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1149\u001b[0m           \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1150\u001b[0;31m             \u001b[0mnp_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubfeed_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubfeed_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1152\u001b[0m           if (not is_tensor_handle_feed and\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/numpy/core/_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m     \"\"\"\n\u001b[0;32m---> 85\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(y_)\n",
    "weights = {\n",
    "    'h1':tf.Variable(tf.truncated_normal([n_dim,n_hidden_1])),\n",
    "    'h2':tf.Variable(tf.truncated_normal([n_hidden_1,n_hidden_2])),\n",
    "    'h3':tf.Variable(tf.truncated_normal([n_hidden_2,n_hidden_3])),\n",
    "    'h4':tf.Variable(tf.truncated_normal([n_hidden_3,n_hidden_4])),\n",
    "    'out':tf.Variable(tf.truncated_normal([n_hidden_4,n_class])),\n",
    "}\n",
    "\n",
    "biases = {\n",
    "    'b1':tf.Variable(tf.truncated_normal([n_hidden_1])),\n",
    "    'b2':tf.Variable(tf.truncated_normal([n_hidden_2])),\n",
    "    'b3':tf.Variable(tf.truncated_normal([n_hidden_3])),\n",
    "    'b4':tf.Variable(tf.truncated_normal([n_hidden_4])),\n",
    "    'out':tf.Variable(tf.truncated_normal([n_class])),\n",
    "}\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "y = multilayer_perceptron(x,weights,biases)\n",
    "\n",
    "cost_function = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = y,labels = y_))\n",
    "training_step = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost_function)\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "mse_history = []\n",
    "accuracy_history = []\n",
    "for epch in range(epoch):\n",
    "    sess.run(training_step,feed_dict = {x:X_train,y_:y_train})\n",
    "    cost = sess.run(cost_function,feed_dict = {x:X_train,y_:y_train})\n",
    "    cost_history = np.append(cost_history,cost)\n",
    "    correct_prediction = tf.equal(tf.argmax(y,1),tf.argmax(y_,1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction,tf.float32))\n",
    "    pred_y = sess.run(y,feed_dict = {x:X_test})\n",
    "    mse = tf.reduce_mean(tf.square(pred_y-y_test))\n",
    "    mse_ = sess.run(mse)\n",
    "    mse_history.append(mse_)\n",
    "    accuracy = sess.run(accuracy,feed_dict={x:X_train,y_:y_train})\n",
    "    accuracy_history.append(accuracy)\n",
    "    print(\"Epoch : {}, Cost : {}, MSE : {}, Train_Accuracy : {}\".format(epch,cost,mse_,accuracy))\n",
    "    if(accuracy>98):\n",
    "        break\n",
    "save_path = saver.save(sess,model_path)\n",
    "print(\"Model saved at : {}\".format(save_path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(mse_history,'r')\n",
    "plt.show()\n",
    "plt.plot(accuracy_history)\n",
    "plt.show()\n",
    "\n",
    "correct_prediction = tf.equal(tf.argmax(y,1),tf.argmax(y_,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction,tf.float32))\n",
    "print(\"Test Accuracy : {}\".format(sess.run(accuracy,feed_dict={x:X_test,y_:y_test})))\n",
    "\n",
    "pred_y = sess.run(y,feed_dict={x:X_test})\n",
    "mse = tf.reduce_mean(tf.square(pred_y-y_test))\n",
    "print(\"MSE : \",format(round(sess.run(mse),4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
